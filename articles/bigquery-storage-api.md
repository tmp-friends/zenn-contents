---
title: "BigQueryStorageAPIã§é«˜é€Ÿã«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹"
emoji: "ğŸ”"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["gcp", "bigquery"]
published: false
publication_name: "dmmdata"
---

## è¦ç´„

- BigQueryAPIã‹ã‚‰BigQueryStorageAPIã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§é«˜é€Ÿã«ãƒ‡ãƒ¼ã‚¿å–å¾—ãŒã§ããŸ
- å…·ä½“çš„ã«ã¯ã€ç´„5.7å„„ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«å¯¾ã—ã¦
  - BigQueryAPI: 2æ™‚é–“20åˆ†
  - BigQueryStorageAPI: 3åˆ†

## èƒŒæ™¯

- VertexAIã®ã‚«ã‚¹ã‚¿ãƒ ã‚¸ãƒ§ãƒ–ä¸Šã§BigQueryAPI(Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒª)ã‚’ç”¨ã„ã¦ã€å„„å˜ä½ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¦ã„ãŸ
- BigQueryAPIã§ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ã‚ã‚Šã€ã‚«ã‚¹ã‚¿ãƒ ã‚¸ãƒ§ãƒ–å…¨ä½“ã®å®Ÿè¡Œã«æ™‚é–“ãŒã‹ã‹ã£ã¦ã—ã¾ã£ã¦ã„ãŸ
- é«˜é€ŸåŒ–ã§ããªã„ã‹èª¿æŸ»ã—ãŸã¨ã“ã‚ã€å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«é–¢ã—ã¦ã¯ã€BigQueryStorageAPIä¸€æŠã¨ã®ã“ã¨

https://qiita.com/n-suzuki/items/a67155ee6fffa07f2707

## BigQueryStorageAPI

### æ¦‚è¦

> The BigQuery Storage Read API provides fast access to BigQuery-managed storage by using an rpc-based protocol.

å…¬å¼Doc

https://cloud.google.com/bigquery/docs/reference/storage/


#### BigQueryAPIã«å¯¾ã—é«˜é€ŸåŒ–ã§ãã¦ã„ã‚‹ç†ç”±

> When you use the Storage Read API, structured data is sent over the wire in a binary serialization format. This allows for additional parallelism among multiple consumers for a set of results.

ä¸Šè¨˜ã®èª¬æ˜ã‹ã‚‰ã€ä»¥ä¸‹ã®2ç‚¹ãŒã‚ã‚Šãã†

- ä¸¦åˆ—å‡¦ç†ãŒã§ãã‚‹
  - ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§è¤‡æ•°ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä½¿ç”¨ã—ã¦å‡¦ç†ã§ãã‚‹
- ãƒ‡ãƒ¼ã‚¿è»¢é€ã®åŠ¹ç‡ãŒè‰¯ã„
  - binary serialization formatã¸ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›ã™ã‚‹

### å®Ÿè£…

- ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```
$ pip install google-cloud-bigquery-storage
```

- pd.DataFrameå½¢å¼ã§å–å¾—ã™ã‚‹ã‚ˆã†ã«å®Ÿè£…ã—ã¦ã¿ã‚‹
  - å…¬å¼Sample: https://github.com/googleapis/python-bigquery-storage/blob/main/samples/to_dataframe/read_table_bqstorage.py

```py
import pandas as pd
from google.cloud.bigquery_storage import BigQueryReadClient, types

class BigQueryStorage:
    """å…¬å¼Doc: https://cloud.google.com/python/docs/reference/bigquerystorage/latest

    å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’é«˜é€Ÿã§èª­ã¿è¾¼ã‚€ãŸã‚ã®Class
    """

    def __init__(self, project_id: str, dataset_id: str) -> None:
        """bigquery_storage.BigQueryReadClientã®ç”Ÿæˆ

        Args:
            project_id (str): GCPã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID
            dataset_id (str): GCPã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆID
        """
        self.project_id = project_id
        self.dataset_id = dataset_id

        self.client = BigQueryReadClient()

    def read(self, table_name: str, columns: list[str]) -> pd.DataFrame:
        """ãƒ†ãƒ¼ãƒ–ãƒ«æŒ‡å®šã§select

        Args:
            table_name (str): å–å¾—ã—ãŸã„ãƒ†ãƒ¼ãƒ–ãƒ«å
            columns (list[str]): å–å¾—ã—ãŸã„ã‚«ãƒ©ãƒ å
        Returns:
            pd.DataFrame: selectã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿
        """
        table = f"projects/{self.project_id}/datasets/{self.dataset_id}/tables/{table_name}"

        requested_session = types.ReadSession()
        requested_session.table = table
        requested_session.data_format = types.DataFormat.ARROW

        requested_session.read_options.selected_fields = columns

        parent = f"projects/{self.project_id}"
        session = self.client.create_read_session(
            parent=parent,
            read_session=requested_session,
            max_stream_count=1,
        )

        # max_stream_count=1ã‚ˆã‚Šã€é…åˆ—ã®0ç•ªç›®ã®è¦ç´ ã‚’å˜ã«æŒ‡å®šã—ã¦ã„ã‚‹
        reader = self.client.read_rows(session.streams[0].name)
        rows = reader.rows(session)

        return rows.to_dataframe()
```

## çµæœ

- ç´„5.7å„„ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®ã‚ˆã†ã«é«˜é€Ÿã«å–å¾—ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸ
  - BigQueryAPI: 2æ™‚é–“20åˆ†

  ![before](/images/bigquery-storage-api.md/before.png)

  - BigQueryStorageAPI: 3åˆ†

  ![after](/images/bigquery-storage-api.md/after.png)


ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å—ä¿¡ãƒã‚¤ãƒˆæ•°ã®å±±ãŒã§ãã¦ã„ã‚‹ç®‡æ‰€ãŒBigQueryã¨ã‚„ã‚Šå–ã‚Šã—ã¦ã„ã‚‹ã“ã¨ã‚’è¡¨ã—ã¦ã„ã‚‹

## å‚™è€ƒ

- TensorFlowã§ã¯ã€`tfio.bigquery.BigQueryClient`ãŒã‚ã‚‹
  - ãã‚Œã„ãªã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦æä¾›ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«åˆã†å ´åˆã¯ã“ã¡ã‚‰ãŒãŠã™ã™ã‚

https://www.tensorflow.org/io/api_docs/python/tfio/bigquery/BigQueryClient

- ä»Šå›ã¯Readã®ã¿ã®ç´¹ä»‹ã¨ãªã£ãŸãŒã€Writeã‚‚ã‚ã‚‹

https://cloud.google.com/bigquery/docs/write-api?hl=ja

## ãŠã‚ã‚Šã«

- è»½ã„å®Ÿè£…ã§å¤§å¹…ã«BigQueryã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—å‡¦ç†ã‚’é«˜é€ŸåŒ–ã§ããŸ
- å®Ÿè£…ã«é–¢ã—ã¦ã€`max_stream_count`ã‚’å¢—ã‚„ã›ã°ã€æ›´ã«é«˜é€ŸåŒ–ã§ããã†
- BigQueryã®å†…éƒ¨æŒ™å‹•ã«ã¤ã„ã¦ã‚‚ã–ã£ãã‚ŠçŸ¥ã‚‹ã“ã¨ãŒã§ãã€å‹‰å¼·ã«ãªã£ãŸ

## å‚è€ƒ

https://qiita.com/n-suzuki/items/a67155ee6fffa07f2707

https://cloud.google.com/bigquery/docs/reference/storage/

https://github.com/googleapis/python-bigquery-storage

https://www.slideshare.net/sutepoi/bigquery-query-optimization
