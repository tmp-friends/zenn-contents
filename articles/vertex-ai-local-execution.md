---
title: "Vertex AI Pipelinesã«ãŠã‘ã‚‹ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ"
emoji: "ğŸ§ª"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["gcp", "vertexai", "docker", "nvidia"]
published: true
publication_name: "dmmdata"
---

## è¦ç´„

- Vertex AI Pipelinesã§ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã™ã‚‹ã«ã¯ä»¥ä¸‹ã®2é€šã‚Šã®æ–¹æ³•ãŒã‚ã‚‹
  - 1. `gcloud ai custom-jobs local-run`ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã†æ–¹æ³•ï¼ˆCustomJobå˜ä½ï¼‰
  - 2. Kubeflow Pipelinesã®LocalRunnerã‚’ä½¿ã†æ–¹æ³•ï¼ˆCustomJobå˜ä½ or Pipelineå˜ä½ï¼‰

## èƒŒæ™¯

- GCPã§æä¾›ã•ã‚Œã¦ã„ã‚‹Vertex AI Pipelinesã‚’ç”¨ã„ã¦ã„ã‚‹
- Vertex AI Pipelinesã§Vertex AI CustomJobã‚’ã¤ãªã’ã¦å‹•ã‹ã—ã¦ã„ã‚‹
- æ¯å›ã®å®Ÿè¡Œã‚’GCPä¸Šã§è¡Œã†ã®ã¯ã€è©¦è¡Œå›æ•°ã®è¦³ç‚¹ã«ãŠã„ã¦å¥½ã¾ã—ããªã„
  - ãƒ­ãƒ¼ã‚«ãƒ«ä¸Šã§Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’pushã—ã¦ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ãƒã‚·ãƒ³ã‚’å‰²ã‚Šå½“ã¦ã€Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’pullã™ã‚‹ã®ã«æ•°åˆ†ã¯ã‹ã‹ã‚‹
- ãƒ­ãƒ¼ã‚«ãƒ«ä¸Šã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ç”¨ã„ã¦ã€å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«ã—ãŸã„

## ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ

ä»¥ä¸‹ã®2é€šã‚Šã®æ–¹æ³•ãŒã‚ã‚‹

1. `gcloud ai custom-jobs local-run`ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã†æ–¹æ³•ï¼ˆCustomJobå˜ä½ï¼‰
2. Kubeflow Pipelinesã®LocalRunnerã‚’ä½¿ã†æ–¹æ³•ï¼ˆCustomJobå˜ä½ or Pipelineå˜ä½ï¼‰

### 1. `gcloud ai custom-jobs local-run`ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã†æ–¹æ³•

- CustomJobã§å‹•ã‹ã—ãŸã„Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ç”¨æ„ã™ã‚‹
- `gcloud ai custom-jobs local-run`ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ

```bash:ã‚³ãƒãƒ³ãƒ‰ä¾‹
gcloud ai custom-jobs local-run \
  --executor-image-uri=sample-custom-job:latest \ # Dockerã‚¤ãƒ¡ãƒ¼ã‚¸
  --script=main.py \ # entrypoint
  --gpu \ # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®GPUã‚’ä½¿ç”¨
  -- \ # ä»¥ä¸‹ã€å¼•æ•°
  --model_path "gs://bucket_name/dir_name/2024-04-19/.../model_path" \
  --dt "2024-04-19" \
  --env "dev" \
  --epochs 10
```

```:å‡ºåŠ›ä¾‹
Package is set to /home/jupyter/dir_name/component_name.
/usr/lib/google-cloud-sdk/platform/bundledpythonunix/lib/python3.11/subprocess.py:1010: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used
  self.stdin = io.open(p2cwrite, 'wb', bufsize)
/usr/lib/google-cloud-sdk/platform/bundledpythonunix/lib/python3.11/subprocess.py:1016: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used
  self.stdout = io.open(c2pread, 'rb', bufsize)
#0 building with "default" instance using docker driver
#1 [internal] load build definition from Dockerfile
#1 transferring dockerfile: 513B done
#1 DONE 0.0s
#2 [internal] load metadata for sample-custom-job:latest
#2 DONE 0.0s
#3 [internal] load .dockerignore
#3 transferring context: 2B done
#3 DONE 0.0s
#4 [1/4] FROM sample-custom-job:latest
#4 CACHED
#5 [internal] load build context
#5 transferring context: 637B done
#5 DONE 0.0s
#6 [2/4] RUN mkdir -m 777 -p /usr/app /home
#6 DONE 0.3s
#7 [3/4] WORKDIR /usr/app
#7 DONE 0.0s
#8 [4/4] COPY [., .]
#8 DONE 0.0s
#9 exporting to image
#9 exporting layers 0.0s done
#9 writing image sha256:5e4e2acc2618b112374cda70d7eef3e7bbbea323c5631abb68b3bc7015709ce0 done
#9 naming to docker.io/cloudai-autogenerated/main.py:20240403.04.17.51.683823 done
#9 DONE 0.0s
A training image is built.
Starting to run ...
```

#### æ³¨æ„ç‚¹

- ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã§ã¯ã€CloudStorageãŒ/gcsã¨ã—ã¦mountã•ã‚Œãªã„ã®ã§ã€ç›´æ¥gs://~ã®ã‚ˆã†ã«URIã‚’æŒ‡å®šã™ã‚‹
  - `--model_path  /gcs/~` -> `--model_path gs://~`

- ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œæ™‚ã«Dockerã‚¤ãƒ¡ãƒ¼ã‚¸è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ã®ã§ã€å®šæœŸçš„ã«rmã™ã‚‹å¿…è¦ãŒã‚ã‚‹
  - å…¬å¼Docã«ã‚ˆã‚‹ã¨ã€Dockerã®çŸ¥è­˜ãŒãªãã¦ã‚‚ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½œæˆã§ãã‚‹ã€ã¨ã„ã†ç‚¹ãŒå£²ã‚Šã®ã‚ˆã†ã§ã€æ¯å›ã®å®Ÿè¡Œã§ã‚¤ãƒ¡ãƒ¼ã‚¸ãŒç”Ÿæˆã•ã‚Œã‚‹

```
$ docker images
REPOSITORY                      TAG                        IMAGE ID       CREATED         SIZE
cloudai-autogenerated/main.py   20240419.01.04.40.926317   5001268ebd42   5 minutes ago   5.61GB
cloudai-autogenerated/main.py   20240418.09.39.55.583863   da9333f40137   16 hours ago    5.61GB
cloudai-autogenerated/main.py   20240418.09.37.53.060252   aca894c902aa   16 hours ago    5.61GB
sample-custom-job               latest                     e03cdcae38a4   20 hours ago    5.61GB
```

### 2. Kubeflow Pipelinesã®LocalRunnerã‚’ä½¿ã†æ–¹æ³•

- ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒä¸Šã§å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’install
  - ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ©Ÿèƒ½ã¯kfp2.5.0ä»¥ä¸Šã®ãŸã‚æ³¨æ„
    - https://github.com/kubeflow/pipelines/blob/aac4408237df86cbffc269b939bded99d76c328e/sdk/RELEASE.md#250

```bash
$ pip install kfp=="2.7.0"
$ pip install google-cloud-pipeline-components=="2.13.0"
```

- CustomJobã§å‹•ã‹ã—ãŸã„Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ç”¨æ„ã™ã‚‹
- Pipelineå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„ã—ã€å®Ÿè¡Œ

```py:pipeline.py
from kfp import dsl, local
from kfp.dsl import Model, Output

local.init(runner=local.DockerRunner())

@dsl.container_component
def task(
    model_path: Output[Model],
    dt: str,
    env: str,
    epochs: int = 5,
):
    return dsl.ContainerSpec(
        image="sample-custom-job:latest", # Dockerã‚¤ãƒ¡ãƒ¼ã‚¸
        command=["python3", "main.py"], # entrypoint
        # å¼•æ•°
        args=[
            "--model_path",
            model_path.path,
            "--dt",
            dt,
            "--env",
            env,
            "--epochs",
            epochs,
        ],
    )

task(dt="2024-04-19", env="dev")
```

```:å‡ºåŠ›ä¾‹
$ python pipeline.py
04:10:36.568 - INFO - Executing task 'task'
04:10:36.568 - INFO - Streamed logs:

    Found image 'sample-custom-job:latest'

...
```

Pipelineå˜ä½ã§ã®å®Ÿè¡Œã‚‚å¯èƒ½

## è£œè¶³

### GPUã‚’ç”¨ã„ãŸå®Ÿè¡Œã«ã¤ã„ã¦

- Kubeflow Pipelinesã®LocalRunnerã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«ã®GPUã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢(NVIDIA CUDA Toolkit, cuDNN)ã«å¯¾ã—ã¦ä¾å­˜ãŒã‚ã‚Šãã†
  - GPUã‚’ç”¨ã„ãŸå‡¦ç†ã‚’ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã—ãŸéš›ã«ã€`error code CUDA driver version is insufficient for CUDA runtime version`ã¨ã„ã†ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸãŸã‚

```py
from kfp import dsl, local

local.init(runner=local.DockerRunner())

@dsl.container_component
def gpu_processing():
    return dsl.ContainerSpec(
        image="gcr.io/google_containers/cuda-vector-add:v0.1",
    )

gpu_processing()
```

```:å‡ºåŠ›
$ python pipeline.py
10:39:44.956 - INFO - Executing task 'gpu-processing'
10:39:44.957 - INFO - Streamed logs:

    Found image 'gcr.io/google_containers/cuda-vector-add:v0.1'

    Failed to allocate device vector A (error code CUDA driver version is insufficient for CUDA runtime version)!
    [Vector addition of 50000 elements]
Traceback (most recent call last):
  File "/home/jupyter/gcp-batch-workflow/vertex_ai_pipelines/owl_top_adult_u2i/pipeline.py", line 39, in <module>
    gpu_processing()
  File "/opt/conda/lib/python3.10/site-packages/kfp/dsl/base_component.py", line 101, in __call__
    return pipeline_task.PipelineTask(
  File "/opt/conda/lib/python3.10/site-packages/kfp/dsl/pipeline_task.py", line 184, in __init__
    self._execute_locally(args=args)
  File "/opt/conda/lib/python3.10/site-packages/kfp/dsl/pipeline_task.py", line 199, in _execute_locally
    self._outputs = task_dispatcher.run_single_task(
  File "/opt/conda/lib/python3.10/site-packages/kfp/local/task_dispatcher.py", line 57, in run_single_task
    outputs, _ = run_single_task_implementation(
  File "/opt/conda/lib/python3.10/site-packages/kfp/local/task_dispatcher.py", line 179, in run_single_task_implementation
    raise RuntimeError(msg)
RuntimeError: Task 'gpu-processing' finished with status FAILURE
```

- ä¸€æ–¹ã§ã€`gcloud ai custom-jobs local-run`ã§ã®å®Ÿè¡Œã¯Dockerå†…ã§é–‰ã˜ã¦ã„ã‚‹ã®ã§GPUã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãŒä¸è¦ã ã£ãŸã‚Šã€ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‚’æ±šã•ãšã«æ¸ˆã¿ãã†
  - NVIDIA Container Toolkitã‚’ç”¨ã„ã¦å®Ÿè¡Œã—ã¦ã„ã‚‹ãŸã‚(?)


:::message
ã“ã“ã‚‰è¾ºã¯èª¿ã¹ãã‚Œã¦ã„ãªã„ã®ã§ã€é–“é•ã£ã¦ã„ã‚‹ç‚¹ãªã©ã‚ã‚Œã°ã‚³ãƒ¡ãƒ³ãƒˆä¸‹ã•ã„
:::

## ãŠã‚ã‚Šã«

- Vertex AI Pipelinesã«ã¯ã€æ¥½ã«ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã§ãã‚‹æ©Ÿèƒ½ãŒæƒã£ã¦ã„ãŸ
- GPUã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã«å¯¾ã™ã‚‹ä¾å­˜ã‚’æŒã¡ãŸããªã„ã®ã§ã€ä»Šå¾Œã¯`gcloud ai custom-jobs local-run`ã‚’ä½¿ã†æ–¹å‘ã§ã„ããŸã„
- ã“ã“ã‚‰è¾ºã®ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã¾ã‚ã‚Šã®æ–‡çŒ®ãŒãƒãƒƒãƒˆä¸Šã«ã‚ã¾ã‚Šãªã‹ã£ãŸã®ã§ã€è¨˜äº‹ã«ã™ã‚‹ã“ã¨ãŒã§ãã¦ã‚ˆã‹ã£ãŸ

## å‚è€ƒ

https://cloud.google.com/vertex-ai/docs/training/containerize-run-code-local?hl=ja

https://www.kubeflow.org/docs/components/pipelines/v2/local-execution/

https://caddi.tech/archives/4850
